{"session_id":"559c8a6c-2f5b-4ec8-9f33-198357a992f6","transcript_path":"C:\\Users\\1\\.claude\\projects\\C--Models-ai-memory-service\\559c8a6c-2f5b-4ec8-9f33-198357a992f6.jsonl","cwd":"C:\\Models\\ai-memory-service","permission_mode":"bypassPermissions","hook_event_name":"PostToolUse","tool_name":"MultiEdit","tool_input":{"file_path":"C:\\Models\\ai-memory-service\\src\\api.rs","edits":[{"old_string":"    // Валидируем query параметр\n    validate_query(&params.query)?","new_string":"    // Валидируем query параметр\n    validate_query(&params.query)?;"},{"old_string":"/// Централизованная валидация query параметра\nfn validate_query(query: &str) -> Result<(), ApiError> {\n    if query.trim().is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n    Ok(())\n}","new_string":"/// Централизованная валидация query параметра с защитой от DoS и инъекций\n/// \n/// # Проверки\n/// - Не пустой после trim\n/// - Длина не более 1000 символов \n/// - Отсутствие опасных символов для предотвращения инъекций\n/// \n/// # Examples\n/// ```\n/// assert!(validate_query(\"valid search\").is_ok());\n/// assert!(validate_query(\"\").is_err());\n/// assert!(validate_query(&\"x\".repeat(1001)).is_err());\n/// ```\nfn validate_query(query: &str) -> Result<(), ApiError> {\n    let trimmed = query.trim();\n    \n    if trimmed.is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n    \n    if trimmed.len() > 1000 {\n        return Err(ApiError::BadRequest(\"Query too long (max 1000 chars)\".to_string()));\n    }\n    \n    // Защита от потенциальных инъекций через опасные символы\n    if trimmed.contains(';') || trimmed.contains(\"--\") || trimmed.contains(\"/*\") {\n        return Err(ApiError::BadRequest(\"Invalid characters in query\".to_string()));\n    }\n    \n    Ok(())\n}"}]},"tool_response":{"filePath":"C:\\Models\\ai-memory-service\\src\\api.rs","edits":[{"old_string":"    // Валидируем query параметр\n    validate_query(&params.query)?","new_string":"    // Валидируем query параметр\n    validate_query(&params.query)?;","replace_all":false},{"old_string":"/// Централизованная валидация query параметра\nfn validate_query(query: &str) -> Result<(), ApiError> {\n    if query.trim().is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n    Ok(())\n}","new_string":"/// Централизованная валидация query параметра с защитой от DoS и инъекций\n/// \n/// # Проверки\n/// - Не пустой после trim\n/// - Длина не более 1000 символов \n/// - Отсутствие опасных символов для предотвращения инъекций\n/// \n/// # Examples\n/// ```\n/// assert!(validate_query(\"valid search\").is_ok());\n/// assert!(validate_query(\"\").is_err());\n/// assert!(validate_query(&\"x\".repeat(1001)).is_err());\n/// ```\nfn validate_query(query: &str) -> Result<(), ApiError> {\n    let trimmed = query.trim();\n    \n    if trimmed.is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n    \n    if trimmed.len() > 1000 {\n        return Err(ApiError::BadRequest(\"Query too long (max 1000 chars)\".to_string()));\n    }\n    \n    // Защита от потенциальных инъекций через опасные символы\n    if trimmed.contains(';') || trimmed.contains(\"--\") || trimmed.contains(\"/*\") {\n        return Err(ApiError::BadRequest(\"Invalid characters in query\".to_string()));\n    }\n    \n    Ok(())\n}","replace_all":false}],"originalFileContents":"//! REST API для AI Memory Service с поддержкой GPT-5-nano оркестратора\n//!\n//! Предоставляет HTTP endpoints для операций с памятью, поиска, инсайтов и оркестрации\n\nuse crate::{\n    secure_orchestration::{SecureOrchestrationConfig, SecureOrchestrationLayer, UserContext},\n    InsightType, MemoryCell, MemoryError, MemoryOrchestrator, MemoryQuery, MemoryService,\n    MemoryType, Priority,\n};\nuse anyhow::Result;\nuse axum::{\n    extract::{Json, Path, Query, State},\n    http::StatusCode,\n    response::{IntoResponse, Response},\n    routing::{delete, get, post},\n    Router,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tower::ServiceBuilder;\nuse tower_http::{\n    compression::CompressionLayer,\n    cors::{Any, CorsLayer},\n    limit::RequestBodyLimitLayer,\n    trace::TraceLayer,\n};\nuse tracing::{debug, info};\nuse uuid::Uuid;\n\n/// Состояние API сервера\n#[derive(Clone)]\npub struct ApiState {\n    memory_service: Arc<MemoryService>,\n    orchestrator: Option<Arc<MemoryOrchestrator>>,\n}\n\n/// Конфигурация API\n#[derive(Debug, Clone, Deserialize)]\npub struct ApiConfig {\n    pub host: String,\n    pub port: u16,\n    pub max_body_size: usize,\n    pub enable_cors: bool,\n    pub enable_compression: bool,\n    pub enable_tracing: bool,\n}\n\nimpl Default for ApiConfig {\n    fn default() -> Self {\n        Self {\n            host: \"0.0.0.0\".to_string(),\n            port: 8080,\n            max_body_size: 10 * 1024 * 1024, // 10MB\n            enable_cors: true,\n            enable_compression: true,\n            enable_tracing: true,\n        }\n    }\n}\n\n// ===== Request/Response структуры =====\n\n/// Запрос на сохранение памяти\n#[derive(Debug, Deserialize)]\npub struct StoreMemoryRequest {\n    pub content: String,\n    pub context_hint: Option<String>,\n    pub memory_type: Option<String>,\n    pub tags: Option<Vec<String>>,\n    pub metadata: Option<HashMap<String, String>>,\n    pub importance: Option<f32>,\n}\n\n/// Ответ на сохранение памяти\n#[derive(Debug, Serialize)]\npub struct StoreMemoryResponse {\n    pub id: Uuid,\n    pub success: bool,\n    pub message: String,\n    pub embedding_dimension: usize,\n}\n\n/// Запрос поиска (для POST)\n#[derive(Debug, Deserialize)]\npub struct SearchRequest {\n    pub query: String,\n    pub limit: Option<usize>,\n    pub memory_types: Option<Vec<String>>,\n    pub context: Option<String>,\n    pub include_related: Option<bool>,\n    pub min_importance: Option<f32>,\n    pub similarity_threshold: Option<f32>,\n}\n\nuse serde::Deserializer;\n\n/// Десериализация comma-separated строки в Vec<String>\nfn deserialize_memory_types<'de, D>(deserializer: D) -> Result<Option<Vec<String>>, D::Error>\nwhere\n    D: Deserializer<'de>,\n{\n    let s: Option<String> = Option::deserialize(deserializer)?;\n    Ok(s.map(|s| {\n        s.split(',')\n            .map(|s| s.trim().to_string())\n            .filter(|s| !s.is_empty())\n            .collect()\n    }))\n}\n\n/// Валидация limit с ограничением максимального значения\nfn deserialize_limit<'de, D>(deserializer: D) -> Result<Option<usize>, D::Error>\nwhere\n    D: Deserializer<'de>,\n{\n    let value: Option<usize> = Option::deserialize(deserializer)?;\n    if let Some(l) = value {\n        if l > 100 {\n            return Err(serde::de::Error::custom(\"limit cannot exceed 100\"));\n        }\n        if l == 0 {\n            return Err(serde::de::Error::custom(\"limit must be greater than 0\"));\n        }\n    }\n    Ok(value)\n}\n\n/// Диапазон допустимых значений для порогов важности и схожести\nconst MIN_THRESHOLD: f32 = 0.0;\nconst MAX_THRESHOLD: f32 = 1.0;\n\n/// Общая валидация порога (0.0-1.0) для устранения дублирования кода\n/// Проверяет что значение конечное и в допустимом диапазоне\nfn validate_threshold<E>(value: f32, field_name: &str) -> Result<f32, E>\nwhere\n    E: serde::de::Error,\n{\n    if value.is_nan() || value.is_infinite() {\n        return Err(E::custom(format!(\"{} must be a finite number\", field_name)));\n    }\n    if value < MIN_THRESHOLD || value > MAX_THRESHOLD {\n        return Err(E::custom(format!(\n            \"{} must be between {} and {}\",\n            field_name, MIN_THRESHOLD, MAX_THRESHOLD\n        )));\n    }\n    Ok(value)\n}\n\n/// Валидация порога важности (0.0-1.0)\n/// Примеры: \"0.75\" -> Ok(Some(0.75)), \"1.5\" -> Err, \"NaN\" -> Err, null -> Ok(None)\nfn deserialize_importance<'de, D>(deserializer: D) -> Result<Option<f32>, D::Error>\nwhere\n    D: Deserializer<'de>,\n{\n    let value: Option<f32> = Option::deserialize(deserializer)?;\n    if let Some(imp) = value {\n        validate_threshold(imp, \"min_importance\")?;\n    }\n    Ok(value)\n}\n\n/// Валидация порога схожести (0.0-1.0)\n/// Примеры: \"0.8\" -> Ok(Some(0.8)), \"2.0\" -> Err, \"-0.1\" -> Err, null -> Ok(None)\nfn deserialize_similarity<'de, D>(deserializer: D) -> Result<Option<f32>, D::Error>\nwhere\n    D: Deserializer<'de>,\n{\n    let value: Option<f32> = Option::deserialize(deserializer)?;\n    if let Some(sim) = value {\n        validate_threshold(sim, \"similarity_threshold\")?;\n    }\n    Ok(value)\n}\n\n/// Параметры поиска для GET запроса\n///\n/// Пример: GET /search?query=example&limit=20&memory_types=Semantic,Episodic&similarity_threshold=0.8\n#[derive(Debug, Deserialize)]\npub struct SearchQueryParams {\n    /// Текст запроса для поиска воспоминаний (обязательный параметр)\n    pub query: String,\n    /// Максимальное количество результатов (по умолчанию 10, макс 100)\n    #[serde(deserialize_with = \"deserialize_limit\", default)]\n    pub limit: Option<usize>,\n    /// Типы памяти для фильтрации (comma-separated: \"Semantic,Episodic\")\n    #[serde(deserialize_with = \"deserialize_memory_types\", default)]\n    pub memory_types: Option<Vec<String>>,\n    /// Контекст поиска для более точных результатов\n    #[serde(default)]\n    pub context: Option<String>,\n    /// Включать связанные воспоминания в результат\n    #[serde(default)]\n    pub include_related: Option<bool>,\n    /// Минимальный порог важности (0.0-1.0)\n    #[serde(deserialize_with = \"deserialize_importance\", default)]\n    pub min_importance: Option<f32>,\n    /// Порог схожести для vector search (0.0-1.0)\n    #[serde(deserialize_with = \"deserialize_similarity\", default)]\n    pub similarity_threshold: Option<f32>,\n}\n\n/// Ответ поиска\n#[derive(Debug, Serialize)]\npub struct SearchResponse {\n    pub results: Vec<MemoryCell>,\n    pub total: usize,\n    pub query_id: Uuid,\n    pub reasoning_chain: Vec<String>,\n    pub confidence: f32,\n    pub recall_time_ms: u64,\n    pub success: bool,\n}\n\n/// Запрос инсайтов\n#[derive(Debug, Deserialize)]\npub struct InsightsRequest {\n    pub context: Option<String>,\n    pub insight_type: Option<String>,\n    pub limit: Option<usize>,\n    pub reasoning_effort: Option<String>, // Для GPT-5-nano: minimal, low, medium, high\n}\n\n/// Ответ инсайтов\n#[derive(Debug, Serialize)]\npub struct InsightsResponse {\n    pub insights: Vec<String>,\n    pub memories_analyzed: usize,\n    pub context: Option<String>,\n    pub reasoning_effort: String,\n    pub model_used: String,\n    pub success: bool,\n}\n\n/// Запрос дистилляции\n#[derive(Debug, Deserialize)]\npub struct DistillationRequest {\n    pub context: Option<String>,\n    pub max_points: Option<usize>,\n    pub reasoning_effort: Option<String>,\n}\n\n/// Ответ дистилляции\n#[derive(Debug, Serialize)]\npub struct DistillationResponse {\n    pub key_points: Vec<String>,\n    pub summary: String,\n    pub original_count: usize,\n    pub compression_ratio: f32,\n    pub success: bool,\n}\n\n/// Запрос оптимизации памяти\n#[derive(Debug, Deserialize)]\npub struct OptimizationRequest {\n    pub context: Option<String>,\n    pub aggressive: Option<bool>,\n    pub reasoning_effort: Option<String>,\n}\n\n/// Ответ оптимизации\n#[derive(Debug, Serialize)]\npub struct OptimizationResponse {\n    pub duplicates_found: usize,\n    pub outdated_found: usize,\n    pub suggestions: Vec<String>,\n    pub compression_ratio: f32,\n    pub space_savings_percent: f32,\n    pub applied: bool,\n    pub success: bool,\n}\n\n/// Ответ об ошибке\n#[derive(Debug, Serialize)]\npub struct ErrorResponse {\n    pub error: String,\n    pub code: u16,\n    pub details: Option<String>,\n    pub success: bool,\n}\n\n/// Тип ошибки API\n#[derive(Debug)]\npub enum ApiError {\n    MemoryError(MemoryError),\n    BadRequest(String),\n    NotFound(String),\n    InternalError(String),\n    Unauthorized(String),\n    RateLimitExceeded,\n}\n\nimpl IntoResponse for ApiError {\n    fn into_response(self) -> Response {\n        let (status, error_message, details) = match self {\n            ApiError::BadRequest(msg) => (StatusCode::BAD_REQUEST, msg, None),\n            ApiError::NotFound(msg) => (StatusCode::NOT_FOUND, msg, None),\n            ApiError::InternalError(msg) => (StatusCode::INTERNAL_SERVER_ERROR, msg, None),\n            ApiError::Unauthorized(msg) => (StatusCode::UNAUTHORIZED, msg, None),\n            ApiError::RateLimitExceeded => (\n                StatusCode::TOO_MANY_REQUESTS,\n                \"Rate limit exceeded\".to_string(),\n                Some(\"Please retry after some time\".to_string()),\n            ),\n            ApiError::MemoryError(e) => (\n                StatusCode::INTERNAL_SERVER_ERROR,\n                \"Memory service error\".to_string(),\n                Some(e.to_string()),\n            ),\n        };\n\n        let body = Json(ErrorResponse {\n            error: error_message,\n            code: status.as_u16(),\n            details,\n            success: false,\n        });\n\n        (status, body).into_response()\n    }\n}\n\nimpl From<MemoryError> for ApiError {\n    fn from(err: MemoryError) -> Self {\n        ApiError::MemoryError(err)\n    }\n}\n\nimpl From<anyhow::Error> for ApiError {\n    fn from(err: anyhow::Error) -> Self {\n        ApiError::InternalError(err.to_string())\n    }\n}\n\n/// Создать роутер API\npub fn create_router(\n    memory_service: Arc<MemoryService>,\n    orchestrator: Option<Arc<MemoryOrchestrator>>,\n    config: ApiConfig,\n) -> Router {\n    let state = ApiState {\n        memory_service,\n        orchestrator,\n    };\n\n    let mut app = Router::new()\n        // Здоровье и статус\n        .route(\"/health\", get(health_check))\n        .route(\"/stats\", get(get_statistics))\n        // Операции с памятью\n        .route(\"/memory\", post(store_memory))\n        .route(\"/memory/:id\", get(get_memory))\n        .route(\"/memory/:id\", delete(delete_memory))\n        .route(\"/memories/recent\", get(get_recent_memories))\n        // API-compatible routes for external tools\n        .route(\"/api/memories\", post(store_memory))\n        .route(\"/api/memories\", get(get_recent_memories))\n        .route(\"/api/memories/:id\", get(get_memory))\n        .route(\"/api/memories/:id\", delete(delete_memory))\n        // Поиск\n        .route(\"/search\", post(search_memories).get(search_memories_get))\n        .route(\"/search/context\", post(search_by_context))\n        .route(\"/search/advanced\", post(advanced_recall))\n        // API-compatible search routes for external tools\n        .route(\"/api/memories/search\", get(search_memories_get))\n        // Контексты\n        .route(\"/contexts\", get(list_contexts))\n        .route(\"/context/:path\", get(get_context_info))\n        // Оркестратор (если доступен)\n        .route(\"/orchestrator/insights\", post(generate_insights))\n        .route(\"/orchestrator/distill\", post(distill_context))\n        .route(\"/orchestrator/optimize\", post(optimize_memory))\n        .route(\"/orchestrator/analyze\", post(analyze_patterns))\n        .route(\"/orchestrator/status\", get(orchestrator_status))\n        .with_state(state);\n\n    // Middleware слои\n    let service_builder =\n        ServiceBuilder::new().layer(RequestBodyLimitLayer::new(config.max_body_size));\n\n    if config.enable_tracing {\n        app = app.layer(TraceLayer::new_for_http());\n    }\n\n    if config.enable_compression {\n        app = app.layer(CompressionLayer::new());\n    }\n\n    if config.enable_cors {\n        app = app.layer(\n            CorsLayer::new()\n                .allow_origin(Any)\n                .allow_methods(Any)\n                .allow_headers(Any),\n        );\n    }\n\n    app.layer(service_builder)\n}\n\n// ===== Обработчики endpoints =====\n\n/// Проверка здоровья\nasync fn health_check(State(state): State<ApiState>) -> impl IntoResponse {\n    let orchestrator_available = state.orchestrator.is_some();\n    let stats = state.memory_service.get_stats().await.ok();\n\n    Json(serde_json::json!({\n        \"status\": \"healthy\",\n        \"service\": \"ai-memory-service\",\n        \"version\": env!(\"CARGO_PKG_VERSION\"),\n        \"orchestrator\": {\n            \"available\": orchestrator_available,\n            \"model\": if orchestrator_available { \"gpt-5-nano\" } else { \"none\" },\n        },\n        \"memory_stats\": stats,\n        \"timestamp\": chrono::Utc::now().to_rfc3339(),\n    }))\n}\n\n/// Получить статистику\nasync fn get_statistics(State(state): State<ApiState>) -> Result<impl IntoResponse, ApiError> {\n    let stats = state.memory_service.get_stats().await?;\n\n    Ok(Json(serde_json::json!({\n        \"statistics\": stats,\n        \"orchestrator_available\": state.orchestrator.is_some(),\n        \"success\": true,\n    })))\n}\n\n/// Сохранить память\nasync fn store_memory(\n    State(state): State<ApiState>,\n    Json(req): Json<StoreMemoryRequest>,\n) -> Result<impl IntoResponse, ApiError> {\n    debug!(\"Storing new memory with context: {:?}\", req.context_hint);\n\n    // Валидация входных данных\n    if req.content.trim().is_empty() {\n        return Err(ApiError::BadRequest(\"Content cannot be empty\".to_string()));\n    }\n\n    if req.content.len() > 1_000_000 {\n        return Err(ApiError::BadRequest(\n            \"Content too large (max 1MB)\".to_string(),\n        ));\n    }\n\n    let id = state\n        .memory_service\n        .store_memory(req.content.clone(), req.context_hint.clone())\n        .await?;\n\n    info!(\"Memory stored successfully: {}\", id);\n\n    Ok(Json(StoreMemoryResponse {\n        id,\n        success: true,\n        message: \"Memory stored successfully\".to_string(),\n        embedding_dimension: 768, // EmbeddingGemma dimension\n    }))\n}\n\n/// Получить память по ID\nasync fn get_memory(\n    State(state): State<ApiState>,\n    Path(id): Path<Uuid>,\n) -> Result<impl IntoResponse, ApiError> {\n    let memory = state\n        .memory_service\n        .get_memory(&id)\n        .await\n        .ok_or_else(|| ApiError::NotFound(format!(\"Memory {} not found\", id)))?;\n\n    Ok(Json(memory))\n}\n\n/// Удалить память\nasync fn delete_memory(\n    State(state): State<ApiState>,\n    Path(id): Path<Uuid>,\n) -> Result<impl IntoResponse, ApiError> {\n    state.memory_service.delete_memory(&id).await?;\n\n    info!(\"Memory deleted: {}\", id);\n\n    Ok(Json(serde_json::json!({\n        \"success\": true,\n        \"message\": format!(\"Memory {} deleted\", id),\n    })))\n}\n\n/// Получить недавние воспоминания\nasync fn get_recent_memories(\n    State(state): State<ApiState>,\n    Query(params): Query<HashMap<String, String>>,\n) -> Result<impl IntoResponse, ApiError> {\n    let limit = params\n        .get(\"limit\")\n        .and_then(|s| s.parse().ok())\n        .unwrap_or(10);\n\n    if limit > 1000 {\n        return Err(ApiError::BadRequest(\n            \"Limit too high (max 1000)\".to_string(),\n        ));\n    }\n\n    let context = params.get(\"context\").map(|s| s.as_str());\n\n    let memories = state.memory_service.get_recent(limit, context).await?;\n\n    Ok(Json(serde_json::json!({\n        \"memories\": memories,\n        \"count\": memories.len(),\n        \"context\": context,\n        \"success\": true,\n    })))\n}\n\n/// Поиск воспоминаний (POST endpoint)\n#[axum::debug_handler]\nasync fn search_memories(\n    State(state): State<ApiState>,\n    Json(req): Json<SearchRequest>,\n) -> Result<Json<SearchResponse>, ApiError> {\n    // Валидация\n    if req.query.trim().is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n\n    let limit = req.limit.unwrap_or(10).min(100);\n\n    let results = state.memory_service.search(&req.query, limit).await?;\n\n    let total = results.len();\n\n    Ok(Json(SearchResponse {\n        results,\n        total,\n        query_id: Uuid::new_v4(),\n        reasoning_chain: vec![format!(\"Searched for: {}\", req.query)],\n        confidence: 0.8,\n        recall_time_ms: 100,\n        success: true,\n    }))\n}\n\n/// Поиск воспоминаний (GET endpoint)\n/// Поддерживает все параметры через query string с валидацией\n#[axum::debug_handler]\nasync fn search_memories_get(\n    State(state): State<ApiState>,\n    Query(params): Query<SearchQueryParams>,\n) -> Result<Json<SearchResponse>, ApiError> {\n    // Валидируем query параметр\n    validate_query(&params.query)?\n\n    let limit = params.limit.unwrap_or(10).min(100); // Защита от DoS атак\n\n    // Измеряем реальное время выполнения поиска для точных метрик\n    let start = tokio::time::Instant::now();\n    let results = state\n        .memory_service\n        .search(&params.query, limit)\n        .await\n        .map_err(|e| {\n            tracing::error!(\"GET search failed: query={}, error={}\", params.query, e);\n            e\n        })?;\n    let recall_time_ms = start.elapsed().as_millis() as u64;\n\n    let total = results.len();\n    tracing::info!(\n        \"GET search completed: query={}, results={}, time={}ms\",\n        params.query,\n        total,\n        recall_time_ms\n    );\n\n    Ok(Json(SearchResponse {\n        results,\n        total,\n        query_id: Uuid::new_v4(),\n        // reasoning_chain содержит базовую информацию о запросе для отладки и трейсинга\n        reasoning_chain: vec![format!(\n            \"GET search for: {} (limit: {}, found: {})\",\n            params.query, limit, total\n        )],\n        confidence: 0.8,\n        recall_time_ms,\n        success: true,\n    }))\n}\n\n/// Поиск по контексту\nasync fn search_by_context(\n    State(state): State<ApiState>,\n    Json(req): Json<SearchRequest>,\n) -> Result<impl IntoResponse, ApiError> {\n    let context = req\n        .context\n        .ok_or_else(|| ApiError::BadRequest(\"Context is required\".to_string()))?;\n\n    let limit = req.limit.unwrap_or(10).min(100);\n\n    let results = state\n        .memory_service\n        .search_by_context(&context, Some(&req.query), limit)\n        .await?;\n\n    Ok(Json(SearchResponse {\n        total: results.len(),\n        results,\n        query_id: Uuid::new_v4(),\n        reasoning_chain: vec![\n            format!(\"Context: {}\", context),\n            format!(\"Query: {:?}\", req.query),\n        ],\n        confidence: 0.85,\n        recall_time_ms: 150,\n        success: true,\n    }))\n}\n\n/// Расширенный поиск с полным recall\n#[axum::debug_handler]\nasync fn advanced_recall(\n    State(state): State<ApiState>,\n    Json(req): Json<SearchRequest>,\n) -> Result<Json<SearchResponse>, ApiError> {\n    let query = MemoryQuery {\n        text: req.query,\n        context_hint: req.context,\n        memory_types: req\n            .memory_types\n            .map(|types| types.iter().filter_map(|t| parse_memory_type(t)).collect()),\n        limit: req.limit,\n        min_importance: req.min_importance,\n        time_range: None,\n        similarity_threshold: req.similarity_threshold,\n        include_related: req.include_related.unwrap_or(false),\n    };\n\n    let recalled = state.memory_service.recall_memory(query).await?;\n\n    let mut all_results = Vec::new();\n    all_results.extend(recalled.semantic_layer.clone());\n    all_results.extend(recalled.contextual_layer.clone());\n    all_results.extend(recalled.detailed_layer.clone());\n\n    // Дедупликация\n    let mut seen = std::collections::HashSet::new();\n    all_results.retain(|m| seen.insert(m.id));\n\n    let total = all_results.len();\n\n    Ok(Json(SearchResponse {\n        results: all_results,\n        total,\n        query_id: recalled.query_id,\n        reasoning_chain: recalled.reasoning_chain,\n        confidence: recalled.confidence,\n        recall_time_ms: recalled.recall_time_ms,\n        success: true,\n    }))\n}\n\n/// Список контекстов\nasync fn list_contexts(State(state): State<ApiState>) -> Result<impl IntoResponse, ApiError> {\n    let contexts = state.memory_service.list_contexts().await?;\n\n    Ok(Json(serde_json::json!({\n        \"contexts\": contexts,\n        \"count\": contexts.len(),\n        \"success\": true,\n    })))\n}\n\n/// Информация о контексте\nasync fn get_context_info(\n    State(state): State<ApiState>,\n    Path(path): Path<String>,\n) -> Result<impl IntoResponse, ApiError> {\n    let context = state\n        .memory_service\n        .get_context(&path)\n        .await\n        .ok_or_else(|| ApiError::NotFound(format!(\"Context {} not found\", path)))?;\n\n    Ok(Json(context))\n}\n\n/// Генерация инсайтов через GPT-5-nano оркестратор\nasync fn generate_insights(\n    State(state): State<ApiState>,\n    Json(req): Json<InsightsRequest>,\n) -> Result<impl IntoResponse, ApiError> {\n    let orchestrator = state\n        .orchestrator\n        .ok_or_else(|| ApiError::BadRequest(\"Orchestrator not available\".to_string()))?;\n\n    // Получаем воспоминания для анализа\n    let limit = req.limit.unwrap_or(100).min(500);\n    let memories = if let Some(context) = &req.context {\n        state\n            .memory_service\n            .search_by_context(context, None, limit)\n            .await?\n    } else {\n        state.memory_service.get_recent(limit, None).await?\n    };\n\n    if memories.is_empty() {\n        return Err(ApiError::NotFound(\n            \"No memories found for analysis\".to_string(),\n        ));\n    }\n\n    // Парсим тип инсайта\n    let insight_type =\n        parse_insight_type(req.insight_type.as_deref()).unwrap_or(InsightType::PatternRecognition);\n\n    // Генерируем инсайты с GPT-5-nano\n    let insights = orchestrator\n        .generate_insights(&memories, insight_type)\n        .await\n        .map_err(|e| ApiError::InternalError(e.to_string()))?;\n\n    // Конвертируем в строки\n    let insight_strings: Vec<String> = insights.iter().map(|mt| format!(\"{:?}\", mt)).collect();\n\n    Ok(Json(InsightsResponse {\n        insights: insight_strings,\n        memories_analyzed: memories.len(),\n        context: req.context,\n        reasoning_effort: req.reasoning_effort.unwrap_or_else(|| \"medium\".to_string()),\n        model_used: \"gpt-5-nano\".to_string(),\n        success: true,\n    }))\n}\n\n/// Дистилляция контекста через GPT-5-nano\nasync fn distill_context(\n    State(state): State<ApiState>,\n    Json(req): Json<DistillationRequest>,\n) -> Result<impl IntoResponse, ApiError> {\n    let orchestrator = state\n        .orchestrator\n        .ok_or_else(|| ApiError::BadRequest(\"Orchestrator not available\".to_string()))?;\n\n    // Получаем воспоминания для дистилляции\n    let memories = if let Some(context) = &req.context {\n        state\n            .memory_service\n            .search_by_context(context, None, 1000)\n            .await?\n    } else {\n        state.memory_service.get_recent(1000, None).await?\n    };\n\n    if memories.is_empty() {\n        return Err(ApiError::NotFound(\n            \"No memories found for distillation\".to_string(),\n        ));\n    }\n\n    let original_count = memories.len();\n\n    // Дистиллируем контекст\n    let context_hint = req.context.as_deref();\n    let distillation_result = orchestrator\n        .distill_context(&memories, context_hint)\n        .await\n        .map_err(|e| ApiError::InternalError(e.to_string()))?;\n\n    // Извлекаем ключевые точки из результата дистилляции\n    // distill_context возвращает MemoryType, который мы конвертируем в ключевые точки\n    let key_points = match distillation_result {\n        MemoryType::Semantic { facts, concepts } => {\n            let mut points = facts;\n            points.extend(concepts);\n            points\n        }\n        MemoryType::Episodic {\n            event,\n            participants,\n            ..\n        } => {\n            let mut points = vec![event];\n            points.extend(participants);\n            points\n        }\n        MemoryType::Procedural { steps, .. } => steps,\n        MemoryType::Working { task, .. } => {\n            vec![task]\n        }\n        MemoryType::Code {\n            functions,\n            concepts,\n            ..\n        } => {\n            let mut points = functions;\n            points.extend(concepts);\n            points\n        }\n        _ => {\n            // Для других типов\n            vec![format!(\n                \"Distilled memory of type: {:?}\",\n                distillation_result\n            )]\n        }\n    };\n\n    let num_points = key_points.len();\n    let compression_ratio = if num_points == 0 {\n        1.0\n    } else {\n        original_count as f32 / num_points as f32\n    };\n\n    // Создаем summary из ключевых точек\n    let summary = if key_points.len() > 3 {\n        format!(\n            \"{} key points extracted from {} memories\",\n            key_points.len(),\n            original_count\n        )\n    } else {\n        key_points.join(\"; \")\n    };\n\n    Ok(Json(DistillationResponse {\n        key_points,\n        summary,\n        original_count,\n        compression_ratio,\n        success: true,\n    }))\n}\n\n/// Оптимизация памяти через GPT-5-nano\nasync fn optimize_memory(\n    State(state): State<ApiState>,\n    Json(req): Json<OptimizationRequest>,\n) -> Result<impl IntoResponse, ApiError> {\n    let orchestrator = state\n        .orchestrator\n        .ok_or_else(|| ApiError::BadRequest(\"Orchestrator not available\".to_string()))?;\n\n    // Получаем воспоминания для оптимизации\n    let memories = if let Some(context) = &req.context {\n        state\n            .memory_service\n            .search_by_context(&context, None, 5000)\n            .await?\n    } else {\n        state.memory_service.get_recent(5000, None).await?\n    };\n\n    if memories.is_empty() {\n        return Ok(Json(OptimizationResponse {\n            duplicates_found: 0,\n            outdated_found: 0,\n            suggestions: vec![\"No memories to optimize\".to_string()],\n            compression_ratio: 1.0,\n            space_savings_percent: 0.0,\n            applied: false,\n            success: true,\n        }));\n    }\n\n    // Оптимизируем хранилище\n    let optimization = orchestrator\n        .optimize_memory_storage(&memories)\n        .await\n        .map_err(|e| ApiError::InternalError(e.to_string()))?;\n\n    // TODO: Применить оптимизацию если aggressive=true\n\n    Ok(Json(OptimizationResponse {\n        duplicates_found: optimization.duplicates_to_remove.len(),\n        outdated_found: optimization.outdated_for_archive.len(),\n        suggestions: optimization.optimization_suggestions,\n        compression_ratio: optimization.compression_ratio,\n        space_savings_percent: optimization.space_savings_percent,\n        applied: req.aggressive.unwrap_or(false),\n        success: true,\n    }))\n}\n\n/// Анализ паттернов через GPT-5-nano\nasync fn analyze_patterns(\n    State(state): State<ApiState>,\n    Json(req): Json<HashMap<String, serde_json::Value>>,\n) -> Result<impl IntoResponse, ApiError> {\n    let orchestrator = state\n        .orchestrator\n        .ok_or_else(|| ApiError::BadRequest(\"Orchestrator not available\".to_string()))?;\n\n    let context = req\n        .get(\"context\")\n        .and_then(|v| v.as_str())\n        .map(String::from);\n\n    let limit = req.get(\"limit\").and_then(|v| v.as_u64()).unwrap_or(100) as usize;\n\n    // Получаем воспоминания для анализа\n    let memories = if let Some(ctx) = context {\n        state\n            .memory_service\n            .search_by_context(&ctx, None, limit)\n            .await?\n    } else {\n        state.memory_service.get_recent(limit, None).await?\n    };\n\n    if memories.is_empty() {\n        return Err(ApiError::NotFound(\n            \"No memories found for analysis\".to_string(),\n        ));\n    }\n\n    // Анализируем паттерны\n    let analysis = orchestrator\n        .analyze_memory_patterns(&memories)\n        .await\n        .map_err(|e| ApiError::InternalError(e.to_string()))?;\n\n    Ok(Json(serde_json::json!({\n        \"analysis\": analysis,\n        \"memories_analyzed\": memories.len(),\n        \"model\": \"gpt-5-nano\",\n        \"success\": true,\n    })))\n}\n\n/// Статус оркестратора\nasync fn orchestrator_status(State(state): State<ApiState>) -> impl IntoResponse {\n    if let Some(_orchestrator) = &state.orchestrator {\n        Json(serde_json::json!({\n            \"available\": true,\n            \"model\": \"gpt-5-nano\",\n            \"features\": {\n                \"distillation\": true,\n                \"insights\": true,\n                \"optimization\": true,\n                \"pattern_analysis\": true,\n            },\n            \"config\": {\n                \"max_input_tokens\": 400000,\n                \"max_output_tokens\": 12000,\n                \"reasoning_effort_levels\": [\"minimal\", \"low\", \"medium\", \"high\"],\n            },\n            \"success\": true,\n        }))\n    } else {\n        Json(serde_json::json!({\n            \"available\": false,\n            \"message\": \"Orchestrator not configured\",\n            \"success\": false,\n        }))\n    }\n}\n\n/// Централизованная валидация query параметра\nfn validate_query(query: &str) -> Result<(), ApiError> {\n    if query.trim().is_empty() {\n        return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));\n    }\n    Ok(())\n}\n\n// ===== Вспомогательные функции =====\n\n/// Парсинг типа памяти из строки\nfn parse_memory_type(s: &str) -> Option<MemoryType> {\n    match s.to_lowercase().as_str() {\n        \"semantic\" => Some(MemoryType::Semantic {\n            facts: vec![],\n            concepts: vec![],\n        }),\n        \"episodic\" => Some(MemoryType::Episodic {\n            event: String::new(),\n            location: None,\n            participants: vec![],\n            timeframe: None,\n        }),\n        \"procedural\" => Some(MemoryType::Procedural {\n            steps: vec![],\n            tools: vec![],\n            prerequisites: vec![],\n        }),\n        \"working\" => Some(MemoryType::Working {\n            task: String::new(),\n            deadline: None,\n            priority: Priority::Medium,\n        }),\n        _ => None,\n    }\n}\n\n/// Парсинг типа инсайта\nfn parse_insight_type(s: Option<&str>) -> Option<InsightType> {\n    s.and_then(|t| match t.to_lowercase().as_str() {\n        \"preference\" | \"user_preference\" => Some(InsightType::UserPreference),\n        \"pattern\" | \"pattern_recognition\" => Some(InsightType::PatternRecognition),\n        \"strategy\" | \"strategy_effectiveness\" => Some(InsightType::StrategyEffectiveness),\n        \"mistake\" | \"common_mistake\" => Some(InsightType::CommonMistake),\n        \"practice\" | \"best_practice\" => Some(InsightType::BestPractice),\n        \"gap\" | \"knowledge_gap\" => Some(InsightType::KnowledgeGap),\n        \"context\" | \"context_understanding\" => Some(InsightType::ContextUnderstanding),\n        \"performance\" => Some(InsightType::Performance),\n        \"error\" | \"error_pattern\" => Some(InsightType::ErrorPattern),\n        \"success\" | \"success_pattern\" => Some(InsightType::SuccessPattern),\n        _ => None,\n    })\n}\n\n/// Запустить API сервер\npub async fn run_server(\n    memory_service: Arc<MemoryService>,\n    orchestrator: Option<Arc<MemoryOrchestrator>>,\n    config: ApiConfig,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let addr = format!(\"{}:{}\", config.host, config.port);\n    let has_orchestrator = orchestrator.is_some();\n    let router = create_router(memory_service, orchestrator, config);\n\n    info!(\"🚀 Starting AI Memory Service API on {}\", addr);\n    info!(\n        \"📡 Orchestrator: {}\",\n        if has_orchestrator {\n            \"GPT-5-nano enabled\"\n        } else {\n            \"disabled\"\n        }\n    );\n\n    let listener = tokio::net::TcpListener::bind(&addr).await?;\n    axum::serve(listener, router).await?;\n\n    Ok(())\n}\n","structuredPatch":[{"oldStart":556,"oldLines":7,"newStart":556,"newLines":7,"lines":["     Query(params): Query<SearchQueryParams>,"," ) -> Result<Json<SearchResponse>, ApiError> {","     // Валидируем query параметр","-    validate_query(&params.query)?","+    validate_query(&params.query)?;"," ","     let limit = params.limit.unwrap_or(10).min(100); // Защита от DoS атак"," "]},{"oldStart":966,"oldLines":11,"newStart":966,"newLines":35,"lines":["     }"," }"," ","-/// Централизованная валидация query параметра","+/// Централизованная валидация query параметра с защитой от DoS и инъекций","+/// ","+/// # Проверки","+/// - Не пустой после trim","+/// - Длина не более 1000 символов ","+/// - Отсутствие опасных символов для предотвращения инъекций","+/// ","+/// # Examples","+/// ```","+/// assert!(validate_query(\"valid search\").is_ok());","+/// assert!(validate_query(\"\").is_err());","+/// assert!(validate_query(&\"x\".repeat(1001)).is_err());","+/// ```"," fn validate_query(query: &str) -> Result<(), ApiError> {","-    if query.trim().is_empty() {","+    let trimmed = query.trim();","+    ","+    if trimmed.is_empty() {","         return Err(ApiError::BadRequest(\"Query cannot be empty\".to_string()));","     }","+    ","+    if trimmed.len() > 1000 {","+        return Err(ApiError::BadRequest(\"Query too long (max 1000 chars)\".to_string()));","+    }","+    ","+    // Защита от потенциальных инъекций через опасные символы","+    if trimmed.contains(';') || trimmed.contains(\"--\") || trimmed.contains(\"/*\") {","+        return Err(ApiError::BadRequest(\"Invalid characters in query\".to_string()));","+    }","+    ","     Ok(())"," }"," "]}],"userModified":false}}