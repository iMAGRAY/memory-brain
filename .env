# AI Memory Service - Environment Configuration Example
# Copy this file to .env and fill in your actual values
# NEVER commit .env file with real credentials to version control

# =============================================================================
# Required: Security Credentials (MUST be set)
# =============================================================================

# Neo4j Database Password (REQUIRED)
# Generate a strong password: openssl rand -base64 32
NEO4J_PASSWORD=srEU8oTqaFXJe9eF2wl6fFQHF

# OpenAI API Key for GPT Orchestrator (REQUIRED for AI features)
# Get from: https://platform.openai.com/api-keys

OPENAI_API_KEY=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

# =============================================================================
# Optional: Service Configuration
# =============================================================================

# Logging Level (debug, info, warn, error)
RUST_LOG=info,ai_memory_service=debug
RUST_BACKTRACE=1

# Service Host and Port
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8080
WORKERS=4
ENVIRONMENT=production

# CORS Configuration (comma-separated origins)
CORS_ORIGINS=*

# =============================================================================
# Optional: Neo4j Configuration
# =============================================================================

# Neo4j Connection Pool Size
NEO4J_POOL_SIZE=10

# =============================================================================
# Optional: Model and Embedding Configuration
# =============================================================================

# Path to your EmbeddingGemma-300m model files
# User must download and mount these separately
# Download command: huggingface-cli download google/embeddinggemma-300m --local-dir ./models/embeddinggemma-300m
MODELS_PATH=./models
EMBEDDING_MODEL_PATH=./models/embeddinggemma-300m
TOKENIZER_PATH=/app/models/embeddinggemma-300m/tokenizer.json

# Embedding Processing Settings
EMBEDDING_BATCH_SIZE=32
MAX_SEQUENCE_LENGTH=2048
EMBEDDING_DIMENSION=512
NORMALIZE_EMBEDDINGS=true
EMBEDDING_PRECISION=float32
USE_SPECIALIZED_PROMPTS=true

# =============================================================================
# Optional: Cache Configuration
# =============================================================================

# L1 Cache (Hot memories in memory)
L1_CACHE_SIZE=1000

# L2 Cache (Warm memories with TTL)
L2_CACHE_SIZE=10000
CACHE_TTL=3600
CACHE_COMPRESSION=true

# =============================================================================
# Optional: AI Brain Configuration
# =============================================================================

# Memory Management
MAX_MEMORIES=100000
IMPORTANCE_THRESHOLD=0.3
CONSOLIDATION_INTERVAL=300
MEMORY_DECAY_RATE=0.01

# =============================================================================
# Optional: GPT Orchestrator Configuration
# =============================================================================

# Model Selection (gpt-4-turbo, gpt-4, gpt-3.5-turbo)
ORCHESTRATOR_MODEL=gpt-4-turbo

# Token Limits
MAX_INPUT_TOKENS=400000
MAX_OUTPUT_TOKENS=12000

# Generation Parameters
ORCHESTRATOR_TEMPERATURE=1.0
ORCHESTRATOR_TIMEOUT=120

# =============================================================================
# Optional: Monitoring (only needed if using --profile monitoring)
# =============================================================================

# Grafana Admin Password
# Generate: openssl rand -base64 16
GRAFANA_PASSWORD=PYyylQaCii1i2LsdG2D3xly55

# =============================================================================
# Advanced: Performance Tuning
# =============================================================================

# Resource Limits (for development/testing)
# Uncomment and adjust based on your system capabilities
# AI_MEMORY_MAX_MEMORY=8G
# AI_MEMORY_MAX_CPU=2.0
# NEO4J_MAX_MEMORY=2G
# NEO4J_MAX_CPU=1.0

# =============================================================================
# Development Settings (optional)
# =============================================================================

# Enable debug features in development
# DEBUG_MODE=false
# ENABLE_METRICS=true
# LOG_REQUESTS=false